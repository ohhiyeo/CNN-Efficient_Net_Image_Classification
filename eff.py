# -*- coding: utf-8 -*-

#####################################################################################
#                                                                                   #
#       Standard:                                                                   #
#       Epoch   0 Time    342.0 lr = 0.002000 avg loss = 0.016711 accuracy = 10.38  #
#       Epoch   1 Time    339.3 lr = 0.041600 avg loss = 0.012989 accuracy = 29.54  #
#       Epoch   2 Time    339.0 lr = 0.081200 avg loss = 0.010873 accuracy = 35.42  #
#       Epoch   3 Time    338.6 lr = 0.120800 avg loss = 0.009820 accuracy = 41.32  #
#       Epoch   4 Time    339.1 lr = 0.160400 avg loss = 0.009088 accuracy = 44.38  #
#       Epoch   5 Time    338.3 lr = 0.200000 avg loss = 0.008535 accuracy = 46.74  #
#       Epoch   6 Time    338.3 lr = 0.199795 avg loss = 0.007995 accuracy = 47.94  #
#       Epoch   7 Time    339.8 lr = 0.199180 avg loss = 0.007604 accuracy = 49.38  #
#       Epoch   8 Time    340.0 lr = 0.198158 avg loss = 0.007319 accuracy = 54.20  #
#       Epoch   9 Time    339.1 lr = 0.196733 avg loss = 0.007079 accuracy = 54.58  #
#       Epoch  10 Time    338.8 lr = 0.194911 avg loss = 0.006851 accuracy = 57.20  #
#       Epoch  11 Time    338.3 lr = 0.192699 avg loss = 0.006709 accuracy = 57.54  #
#       Epoch  12 Time    338.3 lr = 0.190107 avg loss = 0.006525 accuracy = 58.52  #
#       Epoch  13 Time    338.7 lr = 0.187145 avg loss = 0.006418 accuracy = 59.00  #
#       Epoch  14 Time    338.3 lr = 0.183825 avg loss = 0.006292 accuracy = 57.68  #
#       Epoch  15 Time    338.2 lr = 0.180161 avg loss = 0.006183 accuracy = 60.62  #
#       Epoch  16 Time    338.4 lr = 0.176168 avg loss = 0.006044 accuracy = 58.66  #
#       Epoch  17 Time    338.8 lr = 0.171863 avg loss = 0.006002 accuracy = 57.46  #
#       Epoch  18 Time    338.7 lr = 0.167263 avg loss = 0.005905 accuracy = 61.96  #
#       Epoch  19 Time    338.8 lr = 0.162387 avg loss = 0.005786 accuracy = 63.76  #
#       Epoch  20 Time    338.3 lr = 0.157254 avg loss = 0.005743 accuracy = 63.50  #
#       Epoch  21 Time    338.5 lr = 0.151887 avg loss = 0.005629 accuracy = 65.34  #
#       Epoch  22 Time    338.0 lr = 0.146308 avg loss = 0.005604 accuracy = 62.34  #
#       Epoch  23 Time    338.5 lr = 0.140538 avg loss = 0.005490 accuracy = 65.64  #
#       Epoch  24 Time    338.5 lr = 0.134602 avg loss = 0.005404 accuracy = 65.64  #
#       Epoch  25 Time    338.4 lr = 0.128524 avg loss = 0.005331 accuracy = 65.20  #
#       Epoch  26 Time    338.2 lr = 0.122330 avg loss = 0.005273 accuracy = 65.42  #
#       Epoch  27 Time    338.7 lr = 0.116044 avg loss = 0.005185 accuracy = 67.48  #
#       Epoch  28 Time    339.0 lr = 0.109693 avg loss = 0.005093 accuracy = 65.72  #
#       Epoch  29 Time    339.0 lr = 0.103302 avg loss = 0.005028 accuracy = 63.58  #
#       Epoch  30 Time    338.7 lr = 0.096898 avg loss = 0.004962 accuracy = 65.06  #
#       Epoch  31 Time    338.4 lr = 0.090507 avg loss = 0.004843 accuracy = 65.68  #
#       Epoch  32 Time    337.6 lr = 0.084156 avg loss = 0.004794 accuracy = 67.80  #
#       Epoch  33 Time    337.6 lr = 0.077870 avg loss = 0.004692 accuracy = 67.72  #
#       Epoch  34 Time    337.4 lr = 0.071676 avg loss = 0.004609 accuracy = 67.96  #
#       Epoch  35 Time    337.4 lr = 0.065598 avg loss = 0.004525 accuracy = 67.64  #
#       Epoch  36 Time    338.7 lr = 0.059662 avg loss = 0.004437 accuracy = 67.90  #
#       Epoch  37 Time    337.6 lr = 0.053892 avg loss = 0.004353 accuracy = 70.16  #
#       Epoch  38 Time    337.3 lr = 0.048313 avg loss = 0.004280 accuracy = 69.38  #
#       Epoch  39 Time    337.2 lr = 0.042946 avg loss = 0.004178 accuracy = 69.92  #
#       Epoch  40 Time    337.3 lr = 0.037813 avg loss = 0.004097 accuracy = 69.54  #
#       Epoch  41 Time    337.3 lr = 0.032937 avg loss = 0.004007 accuracy = 70.76  #
#       Epoch  42 Time    337.4 lr = 0.028337 avg loss = 0.003928 accuracy = 70.32  #
#       Epoch  43 Time    337.7 lr = 0.024032 avg loss = 0.003853 accuracy = 70.56  #
#       Epoch  44 Time    337.6 lr = 0.020039 avg loss = 0.003755 accuracy = 70.44  #
#       Epoch  45 Time    337.5 lr = 0.016375 avg loss = 0.003695 accuracy = 71.72  #
#       Epoch  46 Time    338.0 lr = 0.013055 avg loss = 0.003603 accuracy = 71.56  #
#       Epoch  47 Time    339.2 lr = 0.010093 avg loss = 0.003547 accuracy = 71.06  #
#       Epoch  48 Time    338.7 lr = 0.007501 avg loss = 0.003501 accuracy = 72.06  #
#       Epoch  49 Time    338.4 lr = 0.005289 avg loss = 0.003451 accuracy = 71.36  #
#       Epoch  50 Time    339.8 lr = 0.003467 avg loss = 0.003432 accuracy = 71.88  #
#       Epoch  51 Time    339.0 lr = 0.002042 avg loss = 0.003396 accuracy = 71.74  #
#       Epoch  52 Time    338.9 lr = 0.001020 avg loss = 0.003373 accuracy = 71.90  #
#       Epoch  53 Time    338.6 lr = 0.000405 avg loss = 0.003371 accuracy = 71.94  #
#       Epoch  54 Time    338.6 lr = 0.000200 avg loss = 0.003368 accuracy = 72.08  #
#                                                                                   #
#                                                                                   #
#####################################################################################

#################################################################################
#                                                                               #
# IMPORT                                                                        #
#                                                                               #
#################################################################################

# torch
import torch
import torch.nn       as     nn
import torch.optim    as     optim
from   torch.autograd import Function

# torch utils
import torchvision
import torchvision.transforms as transforms

# additional libraries
import os
import urllib.request
import zipfile
import time
import math
import numpy             as np
import matplotlib.pyplot as plt

#################################################################################
#                                                                               #
# PARAMETERS                                                                    #
#                                                                               #
#################################################################################

# data
DATA_DIR_1        = 'data'
DATA_DIR_2        = 'data/imagenet64'
DATA_DIR_TRAIN    = 'data/imagenet64/train'
DATA_DIR_TEST     = 'data/imagenet64/val'
DATA_FILE_TRAIN_1 = 'Train1.zip'
DATA_FILE_TRAIN_2 = 'Train2.zip'
DATA_FILE_TRAIN_3 = 'Train3.zip'
DATA_FILE_TRAIN_4 = 'Train4.zip'
DATA_FILE_TRAIN_5 = 'Train5.zip'
DATA_FILE_TEST_1  = 'Val1.zip'
DATA_URL_TRAIN_1  = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train1.zip'
DATA_URL_TRAIN_2  = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train2.zip'
DATA_URL_TRAIN_3  = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train3.zip'
DATA_URL_TRAIN_4  = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train4.zip'
DATA_URL_TRAIN_5  = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train5.zip'
DATA_URL_TEST_1   = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Val1.zip'
DATA_BATCH_SIZE   = 256
DATA_NUM_WORKERS  = 4
DATA_NUM_CHANNELS = 3
DATA_NUM_CLASSES  = 100
DATA_RESIZE       = 64
DATA_CROP         = 56
DATA_MEAN         = (0.485, 0.456, 0.406)
DATA_STD_DEV      = (0.229, 0.224, 0.225)

# model
MODEL_LEVEL_1_BLOCKS   = 1 # used but ignored in model creation
MODEL_LEVEL_2_BLOCKS   = 1
MODEL_LEVEL_3_BLOCKS   = 2
MODEL_LEVEL_4_BLOCKS   = 3
MODEL_LEVEL_5_BLOCKS   = 4
MODEL_LEVEL_1_CHANNELS = 16
MODEL_LEVEL_2_CHANNELS = 24
MODEL_LEVEL_3_CHANNELS = 40
MODEL_LEVEL_4_CHANNELS = 80
MODEL_LEVEL_5_CHANNELS = 160
MODEL_HEAD_CONV_IN_CHANNELS = 320
MODEL_HEAD_CONV_OUT_CHANNELS = 1280

# training
TRAIN_LR_MAX              = 0.2
TRAIN_LR_INIT_SCALE       = 0.01
TRAIN_LR_FINAL_SCALE      = 0.001
TRAIN_LR_INIT_EPOCHS      = 5
TRAIN_LR_FINAL_EPOCHS     = 50 # 100
TRAIN_NUM_EPOCHS          = TRAIN_LR_INIT_EPOCHS + TRAIN_LR_FINAL_EPOCHS
TRAIN_LR_INIT             = TRAIN_LR_MAX*TRAIN_LR_INIT_SCALE
TRAIN_LR_FINAL            = TRAIN_LR_MAX*TRAIN_LR_FINAL_SCALE
TRAIN_INTRA_EPOCH_DISPLAY = 10000

# file
FILE_NAME_CHECK      = 'EffNetStyleCheck.pt'
FILE_NAME_BEST       = 'EffNetStyleBest.pt'
FILE_SAVE            = True
FILE_LOAD            = False
FILE_EXTEND_TRAINING = False
FILE_NEW_OPTIMIZER   = False

#################################################################################
#                                                                               #
# DATA                                                                          #
#                                                                               #
#################################################################################

# create a local directory structure for data storage
if (os.path.exists(DATA_DIR_1) == False):
    os.mkdir(DATA_DIR_1)
if (os.path.exists(DATA_DIR_2) == False):
    os.mkdir(DATA_DIR_2)
if (os.path.exists(DATA_DIR_TRAIN) == False):
    os.mkdir(DATA_DIR_TRAIN)
if (os.path.exists(DATA_DIR_TEST) == False):
    os.mkdir(DATA_DIR_TEST)

# download data
if (os.path.exists(DATA_FILE_TRAIN_1) == False):
    urllib.request.urlretrieve(DATA_URL_TRAIN_1, DATA_FILE_TRAIN_1)
if (os.path.exists(DATA_FILE_TRAIN_2) == False):
    urllib.request.urlretrieve(DATA_URL_TRAIN_2, DATA_FILE_TRAIN_2)
if (os.path.exists(DATA_FILE_TRAIN_3) == False):
    urllib.request.urlretrieve(DATA_URL_TRAIN_3, DATA_FILE_TRAIN_3)
if (os.path.exists(DATA_FILE_TRAIN_4) == False):
    urllib.request.urlretrieve(DATA_URL_TRAIN_4, DATA_FILE_TRAIN_4)
if (os.path.exists(DATA_FILE_TRAIN_5) == False):
    urllib.request.urlretrieve(DATA_URL_TRAIN_5, DATA_FILE_TRAIN_5)
if (os.path.exists(DATA_FILE_TEST_1) == False):
    urllib.request.urlretrieve(DATA_URL_TEST_1, DATA_FILE_TEST_1)

# extract data
with zipfile.ZipFile(DATA_FILE_TRAIN_1, 'r') as zip_ref:
    zip_ref.extractall(DATA_DIR_TRAIN)
with zipfile.ZipFile(DATA_FILE_TRAIN_2, 'r') as zip_ref:
    zip_ref.extractall(DATA_DIR_TRAIN)
with zipfile.ZipFile(DATA_FILE_TRAIN_3, 'r') as zip_ref:
    zip_ref.extractall(DATA_DIR_TRAIN)
with zipfile.ZipFile(DATA_FILE_TRAIN_4, 'r') as zip_ref:
    zip_ref.extractall(DATA_DIR_TRAIN)
with zipfile.ZipFile(DATA_FILE_TRAIN_5, 'r') as zip_ref:
    zip_ref.extractall(DATA_DIR_TRAIN)
with zipfile.ZipFile(DATA_FILE_TEST_1, 'r') as zip_ref:
    zip_ref.extractall(DATA_DIR_TEST)

# transforms
transform_train = transforms.Compose([transforms.RandomResizedCrop(DATA_CROP), transforms.RandomHorizontalFlip(p=0.5), transforms.ToTensor(), transforms.Normalize(DATA_MEAN, DATA_STD_DEV)])
transform_test  = transforms.Compose([transforms.Resize(DATA_RESIZE), transforms.CenterCrop(DATA_CROP), transforms.ToTensor(), transforms.Normalize(DATA_MEAN, DATA_STD_DEV)])

# data sets
dataset_train = torchvision.datasets.ImageFolder(DATA_DIR_TRAIN, transform=transform_train)
dataset_test  = torchvision.datasets.ImageFolder(DATA_DIR_TEST,  transform=transform_test)

# data loader
dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=DATA_BATCH_SIZE, shuffle=True)
dataloader_test  = torch.utils.data.DataLoader(dataset_test,  batch_size=DATA_BATCH_SIZE, shuffle=False)

#################################################################################
#                                                                               #
# NETWORK BUILDING BLOCK                                                        #
#                                                                               #
#################################################################################

# inverted residual block
class InvResBlock(nn.Module):

    # initialization
    # Q: do we need Group Size?
    def __init__(self, Ni, Ne, No, F, S):

        # parent initialization
        # create all of the operators for the inverted residual block in fig 2a
        # of the paper; note that parameter names were chosen to match the paper
        super(InvResBlock, self).__init__()

        if ((Ni==No) and S==1):
          self.id = True
          # self.conv0 = nn.Conv2d(Ni, Ne, kernel_size=1, stride=S, padding=0, dilation=1, groups=1, bias=False, padding_mode='zeros')
          # self.bn = nn.BatchNorm2d(Ne, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        else:
          self.id = False
        
        P = np.floor(F/2).astype(int)
        self.conv1 = nn.Conv2d(Ni, Ne, kernel_size=1, stride=1, padding=0, dilation=1, groups=1, bias=False, padding_mode='zeros')
        self.bn1   = nn.BatchNorm2d(Ne, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu1 = nn.ReLU()
        self.conv2 = nn.Conv2d(Ne, Ne, kernel_size=F, stride=S, padding=P, dilation=1, groups=Ne, bias=False, padding_mode='zeros')
        self.bn2   = nn.BatchNorm2d(Ne, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        self.relu2 = nn.ReLU()
        self.conv3 = nn.Conv2d(Ne, No, kernel_size=1,stride=1, padding=0, dilation=1, groups=1, bias=False, padding_mode='zeros')
        self.bn3   = nn.BatchNorm2d(No, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

        # sum
        # self.relu0 = nn.ReLU()

        


    # forward path
    def forward(self, x):

        # map input x to output y for the inverted residual block in fig 2a of
        # the paper via connecting the operators defined in the initialization
        # and return output y
        if (self.id == True):
          id = x

        res = self.conv1(x)
        res = self.bn1(res)
        res = self.relu1(res)
        res = self.conv2(res)
        res = self.bn2(res)
        res = self.relu2(res)
        res = self.conv3(res)
        res = self.bn3(res)

        y = res

        if (self.id == True):
          y = y+id
        # y = self.relu0(y)

        # return
        return y

#################################################################################
#                                                                               #
# NETWORK                                                                       #
#                                                                               #
#################################################################################

# define
class Model(nn.Module):

    # initialization
    # add necessary parameters to the init function to create the model defined
    # in table 1 of the paper
    def __init__(self, data_num_channels,
                 model_level_1_blocks, model_level_1_channels,
                 model_level_2_blocks, model_level_2_channels,
                 model_level_3_blocks, model_level_3_channels,
                 model_level_4_blocks, model_level_4_channels,
                 model_level_5_blocks, model_level_5_channels,
                 model_head_conv_in_channels, model_head_conv_out_channels, data_num_classes): 

        # parent initialization
        super(Model, self).__init__()
        # create all of the operators for the network defined in table 1 of the
        # paper using a combination of Python, standard PyTorch operators and
        # the previously defined InvResBlock class
        stride1 = 1
        stride2 = 2
        stride3 = 2
        stride4 = 2
        stride5 = 1


        # MODEL_LEVEL_1_BLOCKS   = 1 # used but ignored in model creation
        # MODEL_LEVEL_2_BLOCKS   = 1
        # MODEL_LEVEL_3_BLOCKS   = 2
        # MODEL_LEVEL_4_BLOCKS   = 3
        # MODEL_LEVEL_5_BLOCKS   = 4
        # MODEL_LEVEL_1_CHANNELS = 16
        # MODEL_LEVEL_2_CHANNELS = 24
        # MODEL_LEVEL_3_CHANNELS = 40
        # MODEL_LEVEL_4_CHANNELS = 80
        # MODEL_LEVEL_5_CHANNELS = 160

        #Tail
        self.tail = nn.ModuleList()
        self.tail.append(nn.Conv2d(data_num_channels, model_level_1_channels, kernel_size=3, stride=1, padding=1, dilation=1, groups=1, bias=False, padding_mode='zeros'))
        self.tail.append(nn.BatchNorm2d(model_level_1_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))
        self.tail.append(nn.ReLU())

        # encoder level 1-Body
        self.enc_1 = nn.ModuleList()
        for n in range(model_level_1_blocks - 1):
            self.enc_1.append(InvResBlock(model_level_1_channels, 4*model_level_1_channels, model_level_1_channels, 3, 1))
        self.enc_1.append(InvResBlock(model_level_1_channels, 4*model_level_1_channels, model_level_2_channels, 3, stride1))

        # encoder level 2-Body
        self.enc_2 = nn.ModuleList()
        for n in range(model_level_2_blocks - 1):
            self.enc_2.append(InvResBlock(model_level_2_channels, 4*model_level_2_channels, model_level_2_channels, 3, 1))
        self.enc_2.append(InvResBlock(model_level_2_channels, 4*model_level_2_channels, model_level_3_channels, 3, stride2))

        # encoder level 3-Body
        self.enc_3 = nn.ModuleList()
        for n in range(model_level_3_blocks - 1):
            self.enc_3.append(InvResBlock(model_level_3_channels, 4*model_level_3_channels, model_level_3_channels, 3, 1))
        self.enc_3.append(InvResBlock(model_level_3_channels, 4*model_level_3_channels, model_level_4_channels, 3, stride3))

        # encoder level 4-Body
        self.enc_4 = nn.ModuleList()
        for n in range(model_level_4_blocks - 1):
            self.enc_4.append(InvResBlock(model_level_4_channels, 4*model_level_4_channels, model_level_4_channels, 3, 1))
        self.enc_4.append(InvResBlock(model_level_4_channels, 4*model_level_4_channels, model_level_5_channels, 3, stride4))

        # encoder level 5-Body
        self.enc_5 = nn.ModuleList()
        for n in range(model_level_5_blocks - 1):
            self.enc_5.append(InvResBlock(model_level_5_channels, 4*model_level_5_channels, model_level_5_channels, 3, 1))
        self.enc_5.append(InvResBlock(model_level_5_channels, 4*model_level_5_channels, model_head_conv_in_channels, 3, stride5))

        # decoder-Head
        self.dec = nn.ModuleList()
        self.dec.append(nn.Conv2d(model_head_conv_in_channels,model_head_conv_out_channels, kernel_size = 1, stride=1, padding=0, dilation=1, groups=1, bias=False, padding_mode='zeros'))
        self.dec.append(nn.BatchNorm2d(model_head_conv_out_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))
        self.dec.append(nn.ReLU())
        self.dec.append(nn.AdaptiveAvgPool2d((1, 1)))
        self.dec.append(nn.Flatten())
        self.dec.append(nn.Linear(model_head_conv_out_channels, data_num_classes, bias=True))

    # forward path
    def forward(self, x):

        # map input x to output y for the network defined in table 1 of the
        # paper via connecting the operators defined in the initialization
        # and return output y

        for layer in self.tail:
            x = layer(x)

        # encoder level 1
        for layer in self.enc_1:
            x = layer(x)

        # encoder level 2
        for layer in self.enc_2:
            x = layer(x)

        # encoder level 3
        for layer in self.enc_3:
            x = layer(x)

        # encoder level 4
        for layer in self.enc_4:
            x = layer(x)

        # encoder level 5
        for layer in self.enc_5:
            x = layer(x)

        # decoder
        for layer in self.dec:
            x = layer(x)


        # return
        return x

# create
# add necessary parameters to the init function to create the model defined
# in table 1 of the paper
model = Model(DATA_NUM_CHANNELS,
              MODEL_LEVEL_1_BLOCKS, MODEL_LEVEL_1_CHANNELS,
              MODEL_LEVEL_2_BLOCKS, MODEL_LEVEL_2_CHANNELS,
              MODEL_LEVEL_3_BLOCKS, MODEL_LEVEL_3_CHANNELS,
              MODEL_LEVEL_4_BLOCKS, MODEL_LEVEL_4_CHANNELS,
              MODEL_LEVEL_5_BLOCKS, MODEL_LEVEL_5_CHANNELS,
              MODEL_HEAD_CONV_IN_CHANNELS, MODEL_HEAD_CONV_OUT_CHANNELS, DATA_NUM_CLASSES) 

# enable data parallelization for multi GPU systems
if (torch.cuda.device_count() > 1):
    model = nn.DataParallel(model)
print('Using {0:d} GPU(s)'.format(torch.cuda.device_count()), flush=True)

#################################################################################
#                                                                               #
# ERROR AND OPTIMIZER                                                           #
#                                                                               #
#################################################################################

# error (softmax cross entropy)
criterion = nn.CrossEntropyLoss()

# learning rate schedule
def lr_schedule(epoch):

    # linear warmup followed by 1/2 wave cosine decay
    if epoch < TRAIN_LR_INIT_EPOCHS:
        lr = (TRAIN_LR_MAX - TRAIN_LR_INIT)*(float(epoch)/TRAIN_LR_INIT_EPOCHS) + TRAIN_LR_INIT
    else:
        lr = TRAIN_LR_FINAL + 0.5*(TRAIN_LR_MAX - TRAIN_LR_FINAL)*(1.0 + math.cos(((float(epoch) - TRAIN_LR_INIT_EPOCHS)/(TRAIN_LR_FINAL_EPOCHS - 1.0))*math.pi))

    return lr

# optimizer
optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, dampening=0.0, weight_decay=5e-5, nesterov=True)

#################################################################################
#                                                                               #
# TRAINING                                                                      #
#                                                                               #
#################################################################################

# start epoch
start_epoch = 0

# specify the device as the GPU if present with fallback to the CPU
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# transfer the network to the device
model.to(device)

# load the last checkpoint
if (FILE_LOAD == True):
    checkpoint = torch.load(FILE_NAME_CHECK)
    model.load_state_dict(checkpoint['model_state_dict'])
    if (FILE_NEW_OPTIMIZER == False):
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    if (FILE_EXTEND_TRAINING == False):
        start_epoch = checkpoint['epoch'] + 1

# initialize the epoch
accuracy_best      = 0
start_time_display = time.time()
start_time_epoch   = time.time()

# cycle through the epochs
for epoch in range(start_epoch, TRAIN_NUM_EPOCHS):

    # initialize epoch training
    model.train()
    training_loss = 0.0
    num_batches   = 0
    num_display   = 0

    # set the learning rate for the epoch
    for g in optimizer.param_groups:
        g['lr'] = lr_schedule(epoch)

    # cycle through the training data set
    for data in dataloader_train:

        # extract a batch of data and move it to the appropriate device
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward pass, loss, backward pass and weight update
        outputs = model(inputs)
        loss    = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # update statistics
        training_loss = training_loss + loss.item()
        num_batches   = num_batches + 1
        num_display   = num_display + DATA_BATCH_SIZE

        # display intra epoch results
        if (num_display > TRAIN_INTRA_EPOCH_DISPLAY):
            num_display          = 0
            elapsed_time_display = time.time() - start_time_display
            start_time_display   = time.time()
            print('Epoch {0:3d} Time {1:8.1f} lr = {2:8.6f} avg loss = {3:8.6f}'.format(epoch, elapsed_time_display, lr_schedule(epoch), (training_loss / num_batches) / DATA_BATCH_SIZE), flush=True)

    # initialize epoch testing
    model.eval()
    test_correct = 0
    test_total   = 0

    # no weight update / no gradient needed
    with torch.no_grad():

        # cycle through the testing data set
        for data in dataloader_test:

            # extract a batch of data and move it to the appropriate device
            inputs, labels = data
            inputs, labels = inputs.to(device), labels.to(device)

            # forward pass and prediction
            outputs      = model(inputs)
            _, predicted = torch.max(outputs.data, 1)

            # update test set statistics
            test_total   = test_total + labels.size(0)
            test_correct = test_correct + (predicted == labels).sum().item()

    # epoch statistics
    elapsed_time_epoch = time.time() - start_time_epoch
    start_time_epoch   = time.time()
    print('Epoch {0:3d} Time {1:8.1f} lr = {2:8.6f} avg loss = {3:8.6f} accuracy = {4:5.2f}'.format(epoch, elapsed_time_epoch, lr_schedule(epoch), (training_loss/num_batches)/DATA_BATCH_SIZE, (100.0*test_correct/test_total)), flush=True)

    # save a checkpoint
    if (FILE_SAVE == True):
        torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}, FILE_NAME_CHECK)

    # save the best model
    accuracy_epoch = 100.0 * test_correct / test_total
    if ((FILE_SAVE == True) and (accuracy_epoch >= accuracy_best)):
        torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}, FILE_NAME_BEST)
